---
selected: '2.0'
title: 'Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models'
authors: 'Chani Jung, Dongkwan Kim, Jiho Jin, Jiseon Kim, Yeon Seonwoo, Yejin Choi, Alice Oh, and Hyunwoo Kim'
collection: 'publications'
permalink: '/publications/2024-11-emnlp'
date: '2024-11-12'
venue: 'Empirical Methods in Natural Language Processing (EMNLP)'
type: 'conference'
summary: ''
venueurl: 'https://2024.emnlp.org/'
arxivurl: 'https://arxiv.org/abs/2407.06004'
---

While humans naturally develop theory of mind (ToM), the capability to understand other people's mental states and beliefs, state-of-the-art large language models (LLMs) underperform on simple ToM benchmarks. We posit that we can extend our understanding of LLMs' ToM abilities by evaluating key human ToM precursors -- perception inference and perception-to-belief inference -- in LLMs. We introduce two datasets, Percept-ToMi and Percept-FANToM, to evaluate these precursory inferences for ToM in LLMs by annotating characters' perceptions on ToMi and FANToM, respectively. Our evaluation of eight state-of-the-art LLMs reveals that the models generally perform well in perception inference while exhibiting limited capability in perception-to-belief inference (e.g., lack of inhibitory control). Based on these results, we present PercepToM, a novel ToM method leveraging LLMs' strong perception inference capability while supplementing their limited perception-to-belief inference. Experimental results demonstrate that PercepToM significantly enhances LLM's performance, especially in false belief scenarios.